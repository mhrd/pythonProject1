{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6464439900022723\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.85      0.73      2372\n",
      "           1       0.67      0.56      0.61      1390\n",
      "           2       0.00      0.00      0.00        34\n",
      "           7       0.46      0.09      0.15       561\n",
      "           9       0.00      0.00      0.00         5\n",
      "          12       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.65      4401\n",
      "   macro avg       0.30      0.25      0.25      4401\n",
      "weighted avg       0.62      0.65      0.61      4401\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alias\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Alias\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alias\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alias\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    " import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the cleansed data\n",
    "data = pd.read_csv('data/cleaned_data.csv')\n",
    "\n",
    "# Splitting the data into features and labels\n",
    "X = data.drop('Decision', axis=1)\n",
    "y = data['Decision']\n",
    "\n",
    "# Identifying categorical columns for one-hot encoding\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Splitting the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing: One-hot encode the categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fitting the preprocessor and transforming the training and test feature sets\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Initializing and training the Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred_logreg = logreg.predict(X_test_processed)\n",
    "logreg_accuracy = accuracy_score(y_test, y_pred_logreg)\n",
    "logreg_report = classification_report(y_test, y_pred_logreg)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy}\")\n",
    "print(f\"Logistic Regression Classification Report:\\n{logreg_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9972733469665985\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2372\n",
      "           1       1.00      1.00      1.00      1390\n",
      "           2       0.94      0.97      0.96        34\n",
      "           7       1.00      1.00      1.00       561\n",
      "           9       0.83      1.00      0.91         5\n",
      "          12       1.00      0.95      0.97        39\n",
      "\n",
      "    accuracy                           1.00      4401\n",
      "   macro avg       0.96      0.99      0.97      4401\n",
      "weighted avg       1.00      1.00      1.00      4401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the cleansed data\n",
    "data = pd.read_csv('data/cleaned_data.csv')\n",
    "\n",
    "# Splitting the data into features and labels\n",
    "X = data.drop('Decision', axis=1)\n",
    "y = data['Decision']\n",
    "\n",
    "# Identifying categorical columns for one-hot encoding\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Splitting the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing: One-hot encode the categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fitting the preprocessor and transforming the training and test feature sets\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Initializing and training the Decision Tree model\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "dtree.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred_dtree = dtree.predict(X_test_processed)\n",
    "dtree_accuracy = accuracy_score(y_test, y_pred_dtree)\n",
    "dtree_report = classification_report(y_test, y_pred_dtree)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {dtree_accuracy}\")\n",
    "print(f\"Decision Tree Classification Report:\\n{dtree_report}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9947739150193138\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2372\n",
      "           1       0.99      0.99      0.99      1390\n",
      "           2       0.89      0.91      0.90        34\n",
      "           3       1.00      1.00      1.00       561\n",
      "           4       0.75      0.60      0.67         5\n",
      "           5       0.95      0.95      0.95        39\n",
      "\n",
      "    accuracy                           0.99      4401\n",
      "   macro avg       0.93      0.91      0.92      4401\n",
      "weighted avg       0.99      0.99      0.99      4401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Path to the cleansed data\n",
    "cleansed_data_path = 'data/cleaned_data.csv'\n",
    "\n",
    "# Load the cleansed data\n",
    "data = pd.read_csv(cleansed_data_path)\n",
    "\n",
    "# Encoding the 'Decision' column to ensure it has continuous classes\n",
    "label_encoder = LabelEncoder()\n",
    "data['Decision'] = label_encoder.fit_transform(data['Decision'])\n",
    "\n",
    "# Splitting the data into features and labels\n",
    "X = data.drop('Decision', axis=1)\n",
    "y = data['Decision']\n",
    "\n",
    "# Identifying categorical columns for one-hot encoding\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Splitting the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing: One-hot encode the categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fitting the preprocessor and transforming the training and test feature sets\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Initializing and training the XGBoost model\n",
    "xgboost_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgboost_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred_xgboost = xgboost_model.predict(X_test_processed)\n",
    "xgboost_accuracy = accuracy_score(y_test, y_pred_xgboost)\n",
    "xgboost_report = classification_report(y_test, y_pred_xgboost)\n",
    "\n",
    "print(f\"XGBoost Accuracy: {xgboost_accuracy}\")\n",
    "print(f\"XGBoost Classification Report:\\n{xgboost_report}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Load the cleansed data\n",
    "data_path = 'data/cleaned_data.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Encoding the 'Decision' column to ensure it has continuous classes\n",
    "label_encoder = LabelEncoder()\n",
    "data['Decision'] = label_encoder.fit_transform(data['Decision'])\n",
    "\n",
    "# Splitting the data into features and labels\n",
    "X = data.drop('Decision', axis=1)\n",
    "y = data['Decision']\n",
    "\n",
    "# Identifying categorical columns for one-hot encoding\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Splitting the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing: One-hot encode the categorical features and scale the numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('num', MinMaxScaler(), X.select_dtypes(include=['float64', 'int64']).columns.tolist())\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fitting the preprocessor and transforming the training and test feature sets\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Reshaping input data for LSTM [samples, time steps, features]\n",
    "X_train_processed = X_train_processed.reshape((X_train_processed.shape[0], 1, X_train_processed.shape[1]))\n",
    "X_test_processed = X_test_processed.reshape((X_test_processed.shape[0], 1, X_test_processed.shape[1]))\n",
    "\n",
    "# Converting the labels to categorical for use with softmax activation\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train_processed.shape[1], X_train_processed.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_processed, y_train_categorical, epochs=100, batch_size=32, validation_data=(X_test_processed, y_test_categorical), verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test_processed, y_test_categorical, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-b4f87f36",
   "language": "python",
   "display_name": "PyCharm (pythonProject)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}